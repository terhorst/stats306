{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you turn this problem set in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All). Your code should run from top to bottom with no errors. Failure to do this will result in loss of points.\n",
    "\n",
    "You should not use `install.packages()` anywhere. You may assume that we have already installed all the packages needed to run your code.\n",
    "\n",
    "Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\" and delete the `stop()` functions, as well as your name and collaborators below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"\"  # your uniqname \n",
    "COLLABORATORS = c()  # vector of uniqnames of your collaborators, if any\n",
    "## IMPORTANT: you must also have set your group on Canvas. This is only used as a backup."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "f806389838eeb4c891f9db33c2c8cda7",
     "grade": false,
     "grade_id": "cell-892bf1ae756bcb37",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "library(tidyverse)\n",
    "library(modelr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "deb835cfb55ce9af2379cd2a867580c2",
     "grade": false,
     "grade_id": "cell-f73c39701a1d2ed0",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# STATS 306\n",
    "## Problem Set 10: Regression and Modeling\n",
    "Each problem is worth two points, for a total of 20."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "d80451bfcce1911cb33389ce22f2570a",
     "grade": false,
     "grade_id": "cell-9e6d730e76d4355a",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "#### Problem 1\n",
    "If we regress `y` on `x`, then the regression coefficient gives the average rate of change of `y` with respect to `x`. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "6e67f1aefa318d8cb0b2d81b78763c44",
     "grade": false,
     "grade_id": "cell-32c23065a1f25fc4",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "lm(cty ~ hwy, mpg) %>% coef"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "4d9de03ca896ee658a0d2bec8e0a3a81",
     "grade": false,
     "grade_id": "cell-c54d1866f02177d8",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "This says that if highway mileage increases by one mile per gallon, average city mileage increases by about 0.68 miles per gallon:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "dead62847c47af47b241111c76a43d9a",
     "grade": false,
     "grade_id": "cell-9a94060cdde7d46c",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "dcity = mpg %>% filter(hwy %in% 24:25) %>% \n",
    "                group_by(hwy) %>% summarize(mean(cty)) %>% print\n",
    "diff(dcity[[2]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "fbcef09946a1e741e79f09bb7a682c6f",
     "grade": false,
     "grade_id": "cell-e2220bfe5829bc2c",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "In class we saw that `log(price)` has approximately a linear relationship with `log(carat)`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "286f7813a5196d461711bd5bcdb9df58",
     "grade": false,
     "grade_id": "cell-064a0ab5a5cd8379",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "lm(log(price) ~ log(carat), diamonds) %>% coef"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "306af6dc60cd35e93b35484021cdf3fb",
     "grade": false,
     "grade_id": "cell-d21ef9969df8b0b1",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "What does this regression say about the relationship between __price__ (not `log(price)`) and __carat__ (not `log(carat)`)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "5e23ba89c5b24e1ffb03a7bfc070557f",
     "grade": true,
     "grade_id": "cell-0ad01704f1f557d6",
     "locked": false,
     "points": 2,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "d7371088938a94337bd4f0ee761d157a",
     "grade": false,
     "grade_id": "cell-768d9201fc2fac0c",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "#### Problem 2\n",
    "In lecture we said that regressing `log(price)` on `log(carat)` \"removed\" the effect of size on a diamond's price, enabling us to visualize net effect of cut, color, and clarity on price by looking at the residuals of that regression.\n",
    "\n",
    "If the residuals are not affected by `log(carat)`, then intuitively they should be uncorrelated with `log(carat)`. Verify that this is true by computing the correlation between the residuals and the size predictor in this regression. Due to numerical error it will be very small but not exactly zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "49d5066f37239e686dc24bb6f0463f0f",
     "grade": true,
     "grade_id": "cell-8bff9fb6f94593da",
     "locked": false,
     "points": 1,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "79fe3546d94e143f39be61ca915efb79",
     "grade": false,
     "grade_id": "cell-2bf29ee97e2ef4e6",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Explain why this implies that the predicted values are also uncorrelated with the residuals in a linear regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "57d4fd0793711878a9c411ab136755a1",
     "grade": true,
     "grade_id": "cell-f20b6ff093ff4e88",
     "locked": false,
     "points": 1,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "3aee1a25c5daab4838a50adb00a0fede",
     "grade": false,
     "grade_id": "cell-96b4568e5c3b34d3",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Bootstrapping\n",
    "The standard error of a regression coefficient measures how much that estimate varies if we were to run the same data experiment many times and repeatedly re-fit a linear model. For example, suppose we get data from the following experiment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "d54644871dd3eb5f21c24b5dc1ecfb32",
     "grade": false,
     "grade_id": "cell-363d7c35e1d725a1",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "experiment = function() {\n",
    "    tibble(\n",
    "        x1 = rexp(rate = 10, n = 100),\n",
    "        x2 = rnorm(n = 100),\n",
    "        y = 3 * x1 - 2 * x2 + rnorm(n = 100, sd = .1)\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "96d932a3ff3ccca729a25e47b0eba400",
     "grade": false,
     "grade_id": "cell-84a3be38174bc4de",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "If we regress `y` on `x1` and `x2`, the standard error of `x1` coefficient in estimated to be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "41ffc1518432906034461a6bb2b49b6d",
     "grade": false,
     "grade_id": "cell-a7fee9140793018e",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "experiment_data = experiment()\n",
    "lm(y ~ x1 + x2, experiment_data) %>% summary %>% coef %>% .['x2', 'Std. Error']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "6518f6ebc755a0d9ad296a8d7fa8c474",
     "grade": false,
     "grade_id": "cell-7c5a3e88aa3e93a9",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "We can verify that this is (approximately) correct by repeatedly running the experiment, fitting the linear model, and computing the standard error of the resulting estimates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "49ae176ea94787b2e704313224d7b0d1",
     "grade": false,
     "grade_id": "cell-a4693399920cae45",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "extract_coef = function(df) lm(y ~ x1 + x2, df) %>% coef %>% .[\"x2\"]\n",
    "map(1:1000, ~ experiment()) %>% map_dbl(extract_coef) %>% sd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "97a393a2ae6e856285b3228b40300606",
     "grade": false,
     "grade_id": "cell-355b05d9d36d2f23",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Of course, in real life, we usually do not have the luxury of generating as many new data sets as we want; we just have a single data set. A famous idea in statistics is to use just our one data set to generate many new data sets by sampling the observations with replacement. This is called [bootstrapping][1]; starting with just one data set we \"pull ourselves up by our bootstraps\".\n",
    "\n",
    "[1]: https://en.wikipedia.org/wiki/Bootstrapping_(statistics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "5915c981734b6a4c7a55de756d0e2deb",
     "grade": false,
     "grade_id": "cell-2f41f47e1c4b720d",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "#### Problem 3\n",
    "Write a function `bootstrap_df(df)` which, given a data frame containing `n` rows, returns a new data frame containing `n` rows sampled randomly _with replacement_ from `df`. (The \"with replacement\" part is important for obvious reasons.) For example, if\n",
    "```{r}\n",
    "df = tribble(\n",
    "    ~x, ~y,\n",
    "    1,   2,\n",
    "    3,   4,\n",
    "    5,   6\n",
    ")\n",
    "```\n",
    "then `bootstrap_df(df)` might return:\n",
    "\n",
    "```{r}\n",
    "  x y\n",
    "1 1 2\n",
    "2 1 2\n",
    "3 3 4\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "55917cb2c852711707d88774e29b6bc4",
     "grade": false,
     "grade_id": "cell-ec737ca5706fbedb",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "bootstrap_df = function(df) {\n",
    "    # YOUR CODE HERE\n",
    "    stop()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "716eab63a35cdbe16cbfee68c933f08c",
     "grade": true,
     "grade_id": "cell-7ee57264e3e796af",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "bs = bootstrap_df(sim1)\n",
    "stopifnot(nrow(bs) == nrow(sim1))\n",
    "bs = bootstrap_df(tibble(x = rep(1, 100)))\n",
    "stopifnot(bs$x == 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "92d8f4c79d0c72390024685427075eb5",
     "grade": false,
     "grade_id": "cell-65b7985d62b9a936",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "#### Problem 4\n",
    "Use `bootstrap_df` to generate 1000 bootstrap replicates from `experiment_df` defined above, and use them to verify that the standard error of the `x2` regression coefficient is again $\\approx 0.01$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "a04a3a6677942dbb570cc6d87eff7360",
     "grade": true,
     "grade_id": "cell-7743ffbe788c26c6",
     "locked": false,
     "points": 2,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "42ded4976b2b36867e35cec5029cf41f",
     "grade": false,
     "grade_id": "cell-e1433195e1e94b54",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Notice that the bootstrap is very general: nothing about it is specific to linear regression. This is why it is so popular, because it lets us estimate uncertainty in more complicated models where (unlike regression) we don't have  exact formulas for the standard error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "45b455689d4e7e846420df2fdb403bcd",
     "grade": false,
     "grade_id": "cell-2dd354d2c78b7bb2",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Variable selection\n",
    "In lecture we looked at a few examples of variable (a.k.a. model) selection: given a response variable, and some predictors, we studied residual plots in order to understand which predictors should be added to the model.\n",
    "\n",
    "This procedure works okay for small data sets, but quickly becomes unmanageable on larger data sets. Already with ten predictors, there are $2^{10} = 1024$ different linear models that we could fit (not including interaction terms)! So, on real data, it is usually not possible to do model selection by hand. Some sort of automated procedure is needed.\n",
    "\n",
    "------\n",
    "\n",
    "In this problem you will implement one such procedure, known as *all subsets regression*. The idea is simple: given a response variable $y$ and predictors $x_1, \\dots, x_p$, we fit all possible linear models involving $y$ and different combinations of the $x_i$. For each fitted model we record some measure of the quality of the fit. We select the model that has the highest quality score.\n",
    "\n",
    "\n",
    "If you want a more detailed description of how the algorithm should work, see the notebook [all_subsets_demo.ipynb](all_subsets_demo.ipynb) in this folder.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "bdd7a5ed446a9e3536ad48089936c2f9",
     "grade": false,
     "grade_id": "cell-0b79b758f5e4ec91",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "#### Problem 5\n",
    "Write a function `power_set(v)` which, given a vector `v`, returns a list of all possible subsets of `v` (including the empty set). For example:\n",
    "\n",
    "```{r}\n",
    "> str(power_set(1:3))\n",
    "List of 8\n",
    " $ : int [1:3] 1 2 3\n",
    " $ : int [1:2] 1 2\n",
    " $ : int [1:2] 1 3\n",
    " $ : int 1\n",
    " $ : int [1:2] 2 3\n",
    " $ : int 2\n",
    " $ : int 3\n",
    " $ : NULL\n",
    "> str(power_set(list('a', 'b', 'c')))\n",
    "List of 8\n",
    " $ : chr [1:3] \"a\" \"b\" \"c\"\n",
    " $ : chr [1:2] \"a\" \"b\"\n",
    " $ : chr [1:2] \"a\" \"c\"\n",
    " $ : chr \"a\"\n",
    " $ : chr [1:2] \"b\" \"c\"\n",
    " $ : chr \"b\"\n",
    " $ : chr \"c\"\n",
    " $ : NULL\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "6349716ec05446ec8a9dc201a989cbe7",
     "grade": false,
     "grade_id": "cell-1505631f22f24540",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "power_set <- function(v) {\n",
    "    # YOUR CODE HERE\n",
    "    stop()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "c41312add0d22bf984582e82e732bf12",
     "grade": true,
     "grade_id": "cell-7fa379507ae80ffd",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "stopifnot(setequal(\n",
    "    power_set(list('a', 'b')),\n",
    "    list(c('a', 'b'), c('a'), c('b'), NULL)\n",
    "    ))\n",
    "stopifnot(setequal(\n",
    "    power_set(1:3),\n",
    "    list(1:3, 1:2, 2:3, c(1, 3), 1, 2, 3, NULL)\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "d678ac7339442687632ac95fae76b9e2",
     "grade": false,
     "grade_id": "cell-73f042329e24d260",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "#### Problem 6\n",
    "Use the function you defined in problem 4 to create a function `all_subdfs(df)`. Given a data frame `df`, `all_subdfs(df)` returns a new list of dataframes. Each entry in the list contains a subset of the columns in `df`, and there are as many entries as there are subsets of the columns (i.e., $2^p$ if there are $p$ columns.) \n",
    "\n",
    "For example:\n",
    "```{r}\n",
    "> all_subdfs(tibble(a=1:3, b=2:4, c=c('a','b','c'))) %>% str\n",
    "List of 8\n",
    " $ :Classes ‘tbl_df’, ‘tbl’ and 'data.frame':\t3 obs. of  3 variables:\n",
    "  ..$ a: int [1:3] 1 2 3\n",
    "  ..$ b: int [1:3] 2 3 4\n",
    "  ..$ c: chr [1:3] \"a\" \"b\" \"c\"\n",
    " $ :Classes ‘tbl_df’, ‘tbl’ and 'data.frame':\t3 obs. of  2 variables:\n",
    "  ..$ a: int [1:3] 1 2 3\n",
    "  ..$ b: int [1:3] 2 3 4\n",
    " $ :Classes ‘tbl_df’, ‘tbl’ and 'data.frame':\t3 obs. of  2 variables:\n",
    "  ..$ a: int [1:3] 1 2 3\n",
    "  ..$ c: chr [1:3] \"a\" \"b\" \"c\"\n",
    " $ :Classes ‘tbl_df’, ‘tbl’ and 'data.frame':\t3 obs. of  1 variable:\n",
    "  ..$ a: int [1:3] 1 2 3\n",
    " $ :Classes ‘tbl_df’, ‘tbl’ and 'data.frame':\t3 obs. of  2 variables:\n",
    "  ..$ b: int [1:3] 2 3 4\n",
    "  ..$ c: chr [1:3] \"a\" \"b\" \"c\"\n",
    " $ :Classes ‘tbl_df’, ‘tbl’ and 'data.frame':\t3 obs. of  1 variable:\n",
    "  ..$ b: int [1:3] 2 3 4\n",
    " $ :Classes ‘tbl_df’, ‘tbl’ and 'data.frame':\t3 obs. of  1 variable:\n",
    "  ..$ c: chr [1:3] \"a\" \"b\" \"c\"\n",
    " $ :Classes ‘tbl_df’, ‘tbl’ and 'data.frame':\t3 obs. of  0 variables\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "87a92c2af0c3264c17854cf846837dab",
     "grade": false,
     "grade_id": "cell-5b2c3849fa337c1a",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "library(tidyverse)\n",
    "all_subdfs <- function(df) {\n",
    "    # YOUR CODE HERE\n",
    "    stop()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "b5f7744a97396a303ada444d27d1c7bc",
     "grade": true,
     "grade_id": "cell-ce5e4b5dcb638182",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "stopifnot(setequal(\n",
    "    all_subdfs(tibble(a=1:3, b=2:4)),\n",
    "    list(\n",
    "        tibble(a=1:3),\n",
    "        tibble(b=2:4),\n",
    "        tibble(a=1:3, b=2:4),\n",
    "        tibble()\n",
    "    )\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "b73328a8bf0af4476326d440c708411f",
     "grade": false,
     "grade_id": "cell-329dbbe4690114ea",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "#### Problem 7\n",
    "Use the function you implemented in problem 5 to write a function `all_subsets_reg(df, qual)` which takes a data frame `df` and a function `qual` and implements all-subsets regression. The function `qual(mod)` takes as input a fitted model, and returns a quality score; higher scores are better. You may assume that the first column of `df` is the response variable and is named `y`; the remaining columns of `df` are potential predictors and can have arbitrary names. Your model should always include an intercept term.\n",
    "\n",
    "The function should return a vector containing the names of the predictors that were selected under the best model. For example, if `df` is a tibble with four columns `y`, `x1`, `x2` and `x3`, and \n",
    "the algorithm selects `y ~ x1 + x3` as the best model, the `all_subsets(df, qual)` should return the vector `c(\"x1\", \"x3\")`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "ebcb2ddf80879e74c2f3a87be9962a30",
     "grade": false,
     "grade_id": "cell-1980efd69057697c",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "all_subsets_reg = function(df, qual) {\n",
    "    # YOUR CODE HERE\n",
    "    stop()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "65847e71dc67d46383b52b4730ac9e33",
     "grade": false,
     "grade_id": "cell-be947bed0bea73d6",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "The measure of model quality we will use is [AIC](https://en.wikipedia.org/wiki/Akaike_information_criterion). You don't need to understand how AIC works, but you should know that lower scores of AIC indicate a better model fit. Hence, we define our quality function to be:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "0da31758407c1a4b3263343be17fe145",
     "grade": false,
     "grade_id": "cell-9b668d5601dfeb61",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "qual_aic = function(mdl) -AIC(mdl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "df7737e1d9014866f92499abe2356776",
     "grade": true,
     "grade_id": "cell-c80326a3ca3e6b3a",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "set.seed(1)\n",
    "zero <- vector(\"character\", 0)\n",
    "# if there are no predictors, return empty vector\n",
    "stopifnot(all.equal(all_subsets_reg(tibble(y = 1:10), qual_aic), \n",
    "                    zero))\n",
    "# x perfectly predicts y, so of course we include it\n",
    "stopifnot(all.equal(all_subsets_reg(tibble(y = 1:10, x = y), qual_aic), 'x'))\n",
    "# x2 is nearly co-linear with x1, so we do not include it.\n",
    "stopifnot(setequal(all_subsets_reg(tibble(y = 1:10, \n",
    "                                          x1 = y, \n",
    "                                          x2 = x1 + rnorm(n = 10)),\n",
    "                                   qual_aic),\n",
    "                                   'x1'))\n",
    "# if intercept-only model is selected, again return NULL\n",
    "stopifnot(all.equal(\n",
    "    all_subsets_reg(tibble(y = 1:10, x = rnorm(n = 10)), qual_aic),\n",
    "    zero\n",
    "))\n",
    "# modelr data\n",
    "stopifnot(setequal(all_subsets_reg(select(sim4, y, everything()), qual_aic), \n",
    "                   c(\"x1\", \"x2\")))\n",
    "# iris data\n",
    "data(iris)\n",
    "stopifnot(setequal(all_subsets_reg(iris, qual_aic), \n",
    "                   c(\"Sepal.Width\", \"Petal.Length\", \"Petal.Width\", \"Species\")\n",
    "                   )\n",
    "          )\n",
    "# diamonds data are too big, take subset\n",
    "df = slice(diamonds, 1:1000) %>% rename(ynew=y) %>% select(price, everything())\n",
    "stopifnot(setequal(all_subsets_reg(df, qual_aic), \n",
    "                   c(\"carat\", \"cut\", \"color\", \"clarity\", \"depth\", \n",
    "                     \"table\", \"ynew\", \"z\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "dafe561e832ba3dbef7fdd7186c533f1",
     "grade": false,
     "grade_id": "cell-bbc441db6d783e79",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "#### Problem 8\n",
    "Suppose that instead of AIC we had chosen $R^2$ as our measure of model quality:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "dc16559a935ed1e1976f9f0c9d8f2998",
     "grade": false,
     "grade_id": "cell-7f58678018fad0f9",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "qual_R2 = function(mdl) summary(mdl)$r.squared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "8f4da5541c72f9c00bb9dcd2a7c43def",
     "grade": false,
     "grade_id": "cell-bcac1c9dd09fb752",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Try running `all_subsets_reg(df, qual_R2)` for a few data sets. You should notice a pattern in terms of the variables that get selected. Explain why this pattern occurs. Is $R^2$ appropriate to use for model selection?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "dd48009a4d132d22eb3d12660dfb1487",
     "grade": true,
     "grade_id": "cell-1db1d481c975b22f",
     "locked": false,
     "points": 2,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "839562e725314de218152fa2d87e697f",
     "grade": false,
     "grade_id": "cell-5c041b7bf1baa08f",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Overfitting\n",
    "The previous problem studied variable selection. Why is variable selection necessary at all? Shouldn't we use all the available data, rather than adding only a subset of the predictors to our model? \n",
    "\n",
    "One argument for using fewer variables is parsimony: as we discussed in lecture, simpler models are more interpretable. However, even if we do not care about interpretability, there is another reason for preferring less complex models. In this problem, we will see that reason."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "59032e15739b05aef3861f7da12dfa0c",
     "grade": false,
     "grade_id": "cell-3f3dd1c588a3156a",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "#### Problem 9\n",
    "Write a function `split_data(df, p)` which, given a data frame `df` and a number $p \\in (0, 1)$, returns a list with two named elements, `train` and `test`. The function will randomly sample  (without replacement) $100 \\times p \\%$ of the rows (rounded to the nearest integer) from `df` and assign them to `train`. The remaining rows will be stored in `test`. For example, if `df` is a tibble with 100 rows and two columns then\n",
    "```{r}\n",
    "> split_data(df, p)\n",
    "$train\n",
    "# A tibble: 50 x 2\n",
    "<...>\n",
    "$test\n",
    "# A tibble: 50 x 2\n",
    "<...>\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "7322aaa9e2d0cac8e6f5aafaaefca278",
     "grade": false,
     "grade_id": "cell-8ead8e2b94131a9a",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "split_data = function(df, p) {\n",
    "    # YOUR CODE HERE\n",
    "    stop()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "198ca74a0d4c3ae8f497e48938222f66",
     "grade": true,
     "grade_id": "cell-09760af7622a6f33",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "stopifnot(nrow(split_data(sim1, .5)$train) == 15)\n",
    "stopifnot(nrow(split_data(sim1, .5)$test) == 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "d3b7303b653624ae0ff368d032df0325",
     "grade": false,
     "grade_id": "cell-17927acd0860efdc",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "#### Problem 10\n",
    "Write a function `ssr(df, mod)` which, given a data frame `df` and a model `mod`, returns the sum of squared residuals obtained by applying `mod` to `df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "017367a39baf85720375dbcb5d1ff801",
     "grade": false,
     "grade_id": "cell-40e7f95fff907be2",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "ssr = function(df, mod) {\n",
    "    # YOUR CODE HERE\n",
    "    stop()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "53a8576c212d0c5e64f8b4f2e501560f",
     "grade": true,
     "grade_id": "cell-9d04eec35f808a2b",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "stopifnot(near(ssr(sim1, lm(y ~ x, sim1)), 135.8746, tol=1e-1))\n",
    "stopifnot(near(ssr(sim4, lm(y ~ x1 + x2, sim4)), 1322.714, tol=1e-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "733ba4b0e3d9da70aba83f2a5162bc75",
     "grade": false,
     "grade_id": "cell-d32c8fc6a29cbaf5",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Now we will split the `diamonds` into two halves:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(1)\n",
    "df = split_data(diamonds, .5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "9f4c60a48092d27ad3355ffe69532b3e",
     "grade": false,
     "grade_id": "cell-995fb1882b5d63b0",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "On the training data we will fit two models. The first is `log(price) ~ log(carat)` which we saw in lecture. The second, `log(price) ~ log(carat) + .^2`, contains hundreds more interaction terms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "3530743cc0a099546d6836631a57599c",
     "grade": false,
     "grade_id": "cell-8ceffc0525650c41",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "mod1 = lm(log(price) ~ log(carat), df$train)\n",
    "mod2 = lm(log(price) ~ log(carat) + .^2, df$train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "c31ca59945e42faf19eb2055118c4159",
     "grade": false,
     "grade_id": "cell-7042b0208600dba3",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "`mod2` is a much better predictor of `log(price)` on the training data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "f2bde6c2391a7289d52800dcda132e01",
     "grade": false,
     "grade_id": "cell-4bfaf456e139d2ed",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "ssr(df$train, mod1)\n",
    "ssr(df$train, mod2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "19c681fb9ef95453b0f6f061869e95bf",
     "grade": false,
     "grade_id": "cell-a12ff1f50f4de43a",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "However, `mod2` does much *worse* if we compare them on the test data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "402d47cdc56bf949f9503d58b08844cb",
     "grade": false,
     "grade_id": "cell-3a3bedee86cd3cf8",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "ssr(df$test, mod1)\n",
    "ssr(df$test, mod2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "d12c41201f04bc89f12039f064e354f9",
     "grade": false,
     "grade_id": "cell-7f0be1469c754fc0",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "This is called [overfitting](https://en.wikipedia.org/wiki/Overfitting). `mod2` has so many extra predictors that it can fit not only the actual patterns which are present in `df$train`, but also the random noise in that data. Since the noise is different in `df$test`, `mod2` does a worse job of predicting \"out of sample\"."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.4.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
